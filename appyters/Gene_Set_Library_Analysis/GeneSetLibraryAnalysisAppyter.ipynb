{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%appyter init\n",
    "from appyter import magic\n",
    "magic.init(lambda _ = globals: _())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "# Gene Set Library Analysis Appyter\n",
    "This appyter is designed to perform basic statistics, analysis, and visualizations on a Gene Matrix Transpose (.gmt) file. This will allow bioinformatics researchers to analyze relationships between many different gene sets from several gene set libraries.\n",
    " To create your own GMT file, please see Enrichr. Enrichr, hosted by the Ma'ayan Laboratory at Mt. Sinai Icahn School of Medicine, is a collection of geneset libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import itertools \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pathlib\n",
    "import scanpy as sc\n",
    "from IPython.display import display, FileLink, HTML, Markdown, IFrame\n",
    "import anndata\n",
    "import networkx as nx\n",
    "from statsmodels.stats import multitest as mlt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from maayanlab_bioinformatics.enrichment import crisp\n",
    "from collections import OrderedDict\n",
    "from bokeh.palettes import Category20, Turbo256\n",
    "import statistics as stat\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.models import HoverTool, ColumnDataSource\n",
    "from bokeh.plotting import figure, show, save, output_file\n",
    "from bokeh.models.tickers import FixedTicker\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pyvis.network import Network\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter hide_code\n",
    "\n",
    "\n",
    "{% do SectionField(name='GMTSubmission', title='1. Submit a GMT file', subtitle = 'Sumbit a GMT (Gene Matrix Transpose file) for analysis.', img = 'data-upload-icon.png') %}\n",
    "{% do SectionField(name = 'GMT Descriptive Statistics', title = '2. Descriptive Statistics', subtitle = 'Generate descriptive statistics for the gene sets.', img = 'bar-icon.png') %}\n",
    "{% do SectionField(name = 'Pairwise Similarity Table', title = '3. Pairwise Intersection Table', subtitle = 'In this table, the value in row A, column B, is the size of the intersection of A and B. For a small GMT file,  A ball and stick visualization will also be generated showing significant intersections.', img = 'set-similarity.png') %}\n",
    "{% do SectionField(name = 'Metrics', title = '4. Pairwise Metrics', subtitle = 'Select pairwise metrics to measure pairwise similarities between gene sets. NOTE: For Hierarchical Clustering, you must select yes for one of the options.', img = 'cluster-icon.png') %}\n",
    "{% do SectionField (name = 'UMAP_visualization', title = '5. Scatterplot Visualization', subtitle= 'Visualize relative gene set similarities on an interactive scatterplot.', img = 'scatter-icon.png') %}\n",
    "{% do SectionField(name = 'HC', title = '6. Hierarchical Clustering', subtitle = 'Cluster gene sets and visualize them using a Dendrogram and Heatmap.', img = 'analysis.png') %}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "file = 'static/combined.gmt'\n",
       "int_tbl = True\n",
       "jaccard = True\n",
       "otoc = True\n",
       "umap = True\n",
       "desc_stat = True\n",
       "umap_num_neighbors = 5\n",
       "umap_maxdf = 0.5\n",
       "umap_mindf = 0.25\n",
       "linkage_choice = \"complete\"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%appyter code_exec\n",
    "\n",
    "{% set file =\n",
    "            FileField(\n",
    "                name='gs',\n",
    "                label='Gene Set Files',\n",
    "                default= 'static/combined.gmt',\n",
    "                example={\n",
    "                    'example.gmt': url_for('static', filename = 'combined.gmt')\n",
    "                },\n",
    "    \n",
    "section = 'GMTSubmission',) %}\n",
    "\n",
    "file = {{ file }}\n",
    "\n",
    "\n",
    "\n",
    "int_tbl = {{BoolField(name = 'SimilarityTbl', label = 'Intersection Size Table', default = 'true', description = 'In this table, the value in row A, column B, is the size of the intersection of A and B. If you would like to get a list of genes from a specific intersection of two library terms, please see the Intersection Search Section. Select \\'Yes\\' if you would like to generate a Intersection Size Table. Otherwise, select \\'No\\'', section = 'Pairwise Similarity Table') }}\n",
    "jaccard = {{BoolField(name = 'Jaccard', label = 'Jaccard Metric', default = 'true', description = '', section = 'Metrics') }}\n",
    "otoc = {{BoolField(name = 'Otoc', label = 'Otsuka-Ochiai Metric ', default = 'true', description = '', section = 'Metrics') }}\n",
    "\n",
    "\n",
    "umap = {{ BoolField(name = 'umap', label = 'ScatterPlot Visualization', default = 'true', description = 'Select \\'Yes\\' if you would like to generate a Scatter Plot. Otherwise, select \\'No\\'', section = 'UMAP_visualization')}}\n",
    "desc_stat = {{ BoolField(name = 'desc_stat', label = 'Descriptive Statistics', default = 'true', description = 'Select \\'Yes\\' if you would like to generate Descriptive Statistics. Otherwise, select \\'No\\'', section = 'GMT Descriptive Statistics')}}\n",
    "\n",
    "umap_num_neighbors = {{ IntField(name = 'nneighbors', label = 'Number of Neighbors', default = 5, min = 1, max = 30, description = 'We recommend you leave the default number of neighbors. If the visualization does not cluster, rerun the appyter and change the number slightly.', section = 'UMAP_visualization')}}\n",
    "umap_maxdf = {{ ChoiceField(name = 'max_df', label = 'Max df setting', choices = {'0.5': '0.5', '0.75': '.75', '0.9': '.9', '1.0': '1'}, default = '0.5',  description = 'We recommend you leave the default. If the visualization does not cluster, rerun the appyter and change the value.', section = 'UMAP_visualization')}}\n",
    "umap_mindf = {{ ChoiceField(name = 'min_df', label = 'Min df setting', choices = {'0.1' : '0.1', '0.25' : '0.25', '0.5': '0.5' }, default = '0.25', description = 'We recommend you leave the default. If the visualization does not cluster, rerun the appyter and change the value.', section = 'UMAP_visualization')}}\n",
    "linkage_choice = \"{{ ChoiceField(name = 'Linkage Method', label = 'Linkage Method to Use in Hierarchical Clustering', choices = ['average', 'single', 'complete'], default = 'complete',  description = 'A Linkage method describes how to define distances between clusters. Single performs well on non-globular data. Complete and Average perform well on globular data', section = 'HC') }}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == '' :\n",
    "    raise Exception('Please upload a GMT File!')\n",
    "if file.split('.')[1] != 'gmt':\n",
    "    raise Exception('Invalid File, Please upload a GMT File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_list(gene_list):\n",
    "    ##helper function to convert a gene pd.series to a gene list\n",
    "    ret_list = []\n",
    "    for genes in gene_list:\n",
    "        if type(genes) is str:\n",
    "            ret_list.append(genes)\n",
    "        else: ##pd series case\n",
    "            genes = genes.tolist()        \n",
    "            ret_list.append(' '.join(genes))\n",
    "    return ret_list\n",
    "\n",
    "def load_set(file):\n",
    "    ''' Load a set of files into pairs of labeled sets\n",
    "    '''\n",
    "    lst= []\n",
    "    path = pathlib.Path(file)\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            parsed_line = line.split('\\t')\n",
    "            term, library, genes = parsed_line[0], parsed_line[1], parsed_line[2:]\n",
    "            if genes[-1][:-2] == '\\n':\n",
    "                genes[-1] = genes[-1][:-2] ##trim off newline regex '\\n'\n",
    "            lst.append((term,  library, ' '.join(genes)))\n",
    "    zip_lst = [list(i) for i in zip(*lst)]\n",
    "    term, library, genes = zip_lst[0], zip_lst[1], zip_lst[2]\n",
    "    genes = series_to_list(genes)\n",
    "\n",
    "    df = pd.DataFrame({'Genes': genes, 'Library': library}, index = term)\n",
    "    df = df[~df.index.duplicated(keep = 'first')]\n",
    "    return df              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = load_set(file)\n",
    "except: \n",
    "    print('GMT is not in the proper format!')\n",
    "if df.shape[0] < umap_num_neighbors:\n",
    "    umap_num_neighbors = int(np.ceil(df.shape[0]/2)) ##arbitrary right now. May want to change based on parameter settings\n",
    "    print('Number of Neighbors parameter in scatterplot is too large for the submitted dataset. Resetting number of neighbors to '+ str(umap_num_neighbors)+'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    " <style> .text_cell_render .h1 { font-size: 200%; }</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_FET(set1, set2, background = 20000):\n",
    "    ##inputs: set1, set2 - python sets\n",
    "    ##output: p-value of the fisher exact test\n",
    "    res = crisp.fisher_overlap(set1, set2, n_background_entities= background, preserve_overlap=True)\n",
    "    if res == None:\n",
    "        return 10 ##arbitrary insignificant pvalue\n",
    "    else:\n",
    "        return res.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_OTOC(set1, set2):\n",
    "### calculates the Otsuka-Ochiai coefficient, returns 0 if the empty set is passed\n",
    "    try:\n",
    "        set1_size = len(set1)\n",
    "        set2_size = len(set2)\n",
    "        K = len(set1 & set2)/np.sqrt(set1_size*set2_size)\n",
    "        return K\n",
    "    except: \n",
    "        return 0 ##empty set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_itertuple(str1, str2):\n",
    "    ##given two strings (which should be terms in the given gmt), get the tuple back that will index into the pair_df\n",
    "    ##itertools.combos gives tuples that are alphabetically ordered for strings.\n",
    "    return (str1, str2) if str1 < str2 else (str2, str1) \n",
    "\n",
    "def clean_name(dir_name):\n",
    "    dir_name = dir_name.replace(' ', '_')\n",
    "    dir_name = dir_name.replace('/', '_')\n",
    "    dir_name = dir_name.replace(':', '_')\n",
    "    dir_name = dir_name.replace('(', '_')\n",
    "    dir_name = dir_name.replace(')', '_')\n",
    "    dir_name = dir_name.replace('<', '_')\n",
    "    dir_name = dir_name.replace('>', '_')\n",
    "    dir_name = dir_name.strip()\n",
    "    if len(dir_name) >  60:\n",
    "        dir_name = dir_name[0:30] + '...' + dir_name[-30:]\n",
    "    return dir_name\n",
    "\n",
    "\n",
    "def make_dirs(str1):\n",
    "    if not os.path.exists(f'Intersection_Sets/{str1}'):\n",
    "        os.mkdir(f\"Intersection_Sets/{str1}\")\n",
    "    return\n",
    "        \n",
    "def save_set(str1, str2, intersection_set):\n",
    "    term1, term2 = clean_name(str1), clean_name(str2)\n",
    "    term1, term2 = get_itertuple(term1, term2)\n",
    "    make_dirs(term1)\n",
    "    ##str1, str2 are terms to save set in system by. geneset is set of the intersection set to save\n",
    "    series = pd.Series(list(intersection_set))\n",
    "    full_name = os.path.join(r'Intersection_Sets', term1, term2) \n",
    "    try:\n",
    "        series.to_csv(full_name+'.csv', index = False)\n",
    "    except: \n",
    "        pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BH_test(pair_df, alpha = .05):\n",
    "    #benjamini hochberg multiple test correction\n",
    "    #input: pair_df: pairwise dataframe as described above\n",
    "    #input: alpha: a priori significance level \n",
    "    #output: an extended pair_df dataframe with two new columns, 'BH_sig'- a boolean column where True implies significant overlap and 'BH_corrected_pval' \n",
    "    ##- a  pvalue adjust for multiple hypothesis testing\n",
    "    pvals = pair_df['FET_pval'].tolist()\n",
    "    sig, corrected_pval = mlt.fdrcorrection(pvals, alpha, method = 'indep')\n",
    "    pair_df['BH_sig'] = sig\n",
    "    pair_df['BH_corrected_pval'] = corrected_pval\n",
    "    pair_df['BH_corrected_pval'] = pair_df['BH_corrected_pval'].replace(0, pair_df.loc[pair_df['BH_corrected_pval'] != 0, 'BH_corrected_pval'].min())\n",
    "    pair_df['-log10_BH_pval'] = -np.log10(pair_df['BH_corrected_pval'])\n",
    "#     pair_df['-log10_BH_pval']= pair_df['-log10_BH_pval'].replace(np.inf, pair_df.loc[pair_df['-log10_BH_pval'] != np.inf, '-log10_BH_pval'].max())\n",
    "    return pair_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_str(el):\n",
    "    if type(el) == str:\n",
    "        return el\n",
    "    else:\n",
    "        return ' '.join(el.tolist())\n",
    "\n",
    "def generate_pairs_df(df, background = 20000):\n",
    "    ##inputs: df - pandas dataframe that is the result of GMT_to_df transformation\n",
    "    ##output: pair_df - pandas dataframe whose rows are indexed by a tuple/ pair of terms in the set of Gene set \n",
    "    # #terms and columns represent calculated set properties between the two sets\n",
    "\n",
    "    \n",
    "    os.makedirs(\"Intersection_Sets\", exist_ok = True)\n",
    "    intersection = []\n",
    "    in_A_not_B = []\n",
    "    in_B_not_A = []\n",
    "    union = []\n",
    "    jaccard = []\n",
    "    FET_pval = []\n",
    "\n",
    "    to_set = lambda el: set(series_to_str(el).split(' '))\n",
    "    space_counter = lambda str1: str1.count(\" \") +1\n",
    "    terms = list(df.index.values)\n",
    "    int_df = pd.DataFrame(index = terms, columns = terms)\n",
    "    jac_df = pd.DataFrame(index = terms, columns = terms)\n",
    "    otoc_df = pd.DataFrame(index = terms, columns = terms)\n",
    "    pairwise_perms = list(itertools.combinations(terms,2))\n",
    "    for term1,term2 in pairwise_perms:\n",
    "        setA, setB = df.loc[term1]['Genes'], df.loc[term2]['Genes']\n",
    "        set1, set2 = to_set(setA), to_set(setB)\n",
    "        intersect = set1 & set2\n",
    "        save_set(term1, term2, intersect)\n",
    "\n",
    "\n",
    "        union_set = set1 | set2\n",
    "        intersection.append(' '.join(list(intersect)))\n",
    "        in_A_not_B.append(' '.join(list(set1 -set2)))\n",
    "        in_B_not_A.append(' '.join(list(set2 - set1)))\n",
    "        union.append(' '.join(list(union_set)))\n",
    "        pval = calculate_FET(set1, set2)\n",
    "        FET_pval.append(pval)\n",
    "\n",
    "        int_size = len(intersect)\n",
    "        uni_size = len(union_set)\n",
    "        jaccard = \"{:.2f}\".format(int_size/uni_size)\n",
    "        \n",
    "        term1_c, term2_c = get_itertuple(clean_name(term1), clean_name(term2)) ##clean and reorder the terms to the appropriate directory mapping\n",
    "        \n",
    "        jac_df.loc[term1, term2] = jaccard\n",
    "        jac_df.loc[term2, term1] = jaccard\n",
    "        \n",
    "        otoc = \"{:.2f}\".format(calculate_OTOC(set1, set2))\n",
    "        otoc_df.loc[term1, term2] = otoc\n",
    "        otoc_df.loc[term2, term1] = otoc\n",
    "        \n",
    "        \n",
    "        \n",
    "        if int_size != 0:\n",
    "            int_df.loc[term1, term2] = f'<div class = \"df-wrap\" style = \"border: 1px solid; font-weight:bold; background-color: Floralwhite; 2px; height: 1.5em; width: 21px; border-radius: 4px; color: black; float: right; text-align: center\"><a style = \"text-decoration: none; color: black;\" href = \"Intersection_Sets/{term1_c}/{term2_c}.csv\">{int_size}</a></div>'\n",
    "            int_df.loc[term2,term1] =  f'<div class = \"df-wrap\" style = \"border: 1px solid; font-weight:bold; background-color: Floralwhite;  height: 1.5em; width: 21px; border-radius: 4px; color: black; float: right; text-align: center\"><a style = \"text-decoration: none; color: black;\" href = \"Intersection_Sets/{term1_c}/{term2_c}.csv\">{int_size}</a></div>'\n",
    "        else:\n",
    "            int_df.loc[term1,term2] = 0\n",
    "            int_df.loc[term2,term1] = 0\n",
    "\n",
    "\n",
    "\n",
    "    pair_df = pd.DataFrame({'Intersection' : intersection, 'A-B' : in_A_not_B, 'B-A' : in_B_not_A, 'Union': union, 'FET_pval': FET_pval}, index = pairwise_perms)\n",
    "    pair_df['intersect_size'] = pair_df['Intersection'].map(space_counter)\n",
    "    pair_df['union_size'] = pair_df['Union'].map(space_counter)\n",
    "    pair_df['Jaccard'] = pair_df['intersect_size'] / pair_df['union_size']\n",
    "    pair_df = BH_test(pair_df)\n",
    "\n",
    "    \n",
    "    np.fill_diagonal(int_df.values, 0)\n",
    "    np.fill_diagonal(jac_df.values, str(0))\n",
    "    np.fill_diagonal(otoc_df.values, str(0))\n",
    "    \n",
    "    \n",
    "\n",
    "    return pair_df, int_df, jac_df, otoc_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_df, int_df, jac_df, otoc_df = generate_pairs_df(df) ##this may take a minute to complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown \n",
    "## 1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_stats(df, pair_df):\n",
    "    geneset_lst = df['Genes'].to_list()\n",
    "    geneset_lst = [l.split(' ') for l in geneset_lst]\n",
    "    gene_count = {}\n",
    "    sig_term_count = {}\n",
    "    geneset_size = []\n",
    "    num_lib = len(df['Library'].unique()) ## for sizing the x, y axis\n",
    "    num_terms = df.shape[0]\n",
    "\n",
    "    for gene_set in geneset_lst:\n",
    "        geneset_size.append(len(gene_set))\n",
    "        for gene in gene_set:\n",
    "            if gene in gene_count:\n",
    "                gene_count[gene] +=1\n",
    "            else:\n",
    "                gene_count[gene] =1\n",
    "                \n",
    "    sig_df = pair_df[pair_df['BH_sig'] == True]\n",
    "    sig_pairs = list(sig_df.index.values)\n",
    "    sig_pair_lst = list(itertools.chain(*sig_pairs))\n",
    "    for term in sig_pair_lst:\n",
    "        if term in sig_term_count:\n",
    "            sig_term_count[term] +=1\n",
    "        else:\n",
    "            sig_term_count[term] = 1\n",
    "    sig_term_lst = list(sig_term_count.values())\n",
    "    \n",
    "    num_genes = len(gene_count)\n",
    "    num_genesets = len(geneset_size)\n",
    "    \n",
    "    lst_stats = lambda lst, stat_name: {'Statistic': stat_name, 'Average': stat.mean(lst), 'Median': stat.median(lst), 'Standard Deviation': stat.stdev(lst), 'Maximum': max(lst), 'Minimum': min(lst)}\n",
    "    gene_occurence_lst = list(gene_count.values())\n",
    "    \n",
    "    \n",
    "    gene_occ_stats = lst_stats (gene_occurence_lst, 'Gene Occurence')\n",
    "    sig_terms_stats = lst_stats(sig_term_lst, 'Significant Pairwise Intersections')\n",
    "    geneset_stats = lst_stats(geneset_size, 'Gene Set Size')\n",
    "    \n",
    "    \n",
    "    data = [gene_occ_stats, geneset_stats, sig_terms_stats]\n",
    "    stat_df = pd.DataFrame.from_dict(data)\n",
    "    stat_df.set_index('Statistic')\n",
    "    stat_df.round(2)\n",
    "    \n",
    "    return stat_df, gene_count, sig_term_count, geneset_size, num_genes, num_genesets, num_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desc_stat:\n",
    "    stat_df, gene_count, sig_term_count, geneset_size, num_genes, num_genesets, num_lib = basic_stats(df, pair_df)\n",
    "    stat_df = stat_df.round(3)\n",
    "\n",
    "    \n",
    "    html_string= f'''<div><br><br><strong style = \"font-size: 400%;\"> GMT Statistics</strong><br><br><strong style = \n",
    "    \"font-size: 250%;\"> Gene Sets:   {num_genesets}</strong><br><br><strong style = \"font-size: 250%;\"> Unique Genes:  {num_genes}</strong>\n",
    "    <br><br><strong style = \"font-size: 250%;\"> Unique Libraries:  {num_lib}</strong><br><br><div style = \"padding-left\"> {stat_df.to_html(index = False)}</div></div>'''\n",
    "\n",
    "    display(HTML(html_string))\n",
    "    os.makedirs(\"gene_stats\", exist_ok = True)\n",
    "    stat_df.to_csv(\"gene_stats/basic_stats.csv\")\n",
    "    display(Markdown(f\"*Table 1. Basic Statistics*\"))\n",
    "    display(FileLink('gene_stats/basic_stats.csv', result_html_prefix = str(r'Download Table 1:         ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(lst):\n",
    "    array = np.array(lst)\n",
    "    Q1 = np.quantile(array, 0.25)\n",
    "    Q3 = np.quantile(array, 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper = Q3 + 1.5*IQR\n",
    "    upper_indices = np.where(array >=upper)[0]\n",
    "    array = np.delete(array, upper_indices)  \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_histogram(fig_num, xlab, ylab, lst, outliers_removed = True):\n",
    "    if outliers_removed == False:\n",
    "        hist, edges = np.histogram(lst, bins = np.arange(0, max(lst)))\n",
    "    else:\n",
    "        if xlab == 'Genes in Gene Set':\n",
    "            hist, edges = np.histogram(remove_outliers(lst))\n",
    "            edges = np.linspace(0, edges[-1]+1, 11)\n",
    "            \n",
    "        else:\n",
    "            hist, edges = np.histogram(remove_outliers(lst), bins = np.arange(0, max(lst)))\n",
    "    p = figure(width=700, height=500,\n",
    "        x_axis_label = xlab,\n",
    "        y_axis_label  = ylab, \n",
    "        tools = ['save'] )\n",
    "    p.yaxis.axis_label_text_font_size = \"18pt\"\n",
    "    p.xaxis.axis_label_text_font_size = \"18pt\"\n",
    "    p.xaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.yaxis.axis_label_text_font_style = \"bold\"\n",
    "    p.xaxis.major_tick_line_color = None  \n",
    "    p.xaxis.minor_tick_line_color = None\n",
    "    p.yaxis.major_tick_line_color = None  \n",
    "    p.yaxis.minor_tick_line_color = None\n",
    "    if xlab == 'Genes in Gene Set':\n",
    "        p.xaxis.ticker = FixedTicker(ticks = edges )\n",
    "    p.xaxis.major_label_text_font_size= \"15pt\"\n",
    "    p.yaxis.major_label_text_font_size = \"15pt\"\n",
    "    \n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "         fill_color=\"black\", line_color=\"white\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    show(p)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desc_stat:\n",
    "    make_histogram(1, \"Sets\", \"Genes\", list(gene_count.values()), outliers_removed = False)\n",
    "    display(Markdown(\"*Figure 1. Gene Frequency Distribution*\"))\n",
    "\n",
    "    make_histogram(2, \"Genes in Gene Set\", \"Gene Sets\", geneset_size)\n",
    "    display(Markdown(\"*Figure 2. Gene Set Size Distribution*\"))\n",
    "\n",
    "    make_histogram(3, \"Significant Intersections\", \"Gene Sets\", list(sig_term_count.values()))\n",
    "    display(Markdown(\"*Figure 3. Significant Pairwise Intersections*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BH_sig_pairs(sig_df, top_results = 10):\n",
    "    sig_df = pair_df[pair_df['BH_sig'] == True]\n",
    "    sig_df = sig_df.sort_values(by = '-log10_BH_pval', ascending = False)\n",
    "    sig_df_size = sig_df.shape[0]\n",
    "    os.makedirs(\"pvalues\", exist_ok = True)\n",
    "    sig_df.to_csv(\"pvalues/\" + \"log10_BH_Corrected_P-values.csv\")\n",
    "    sig_df = sig_df[0:top_results].sort_values(by = '-log10_BH_pval', ascending = True)\n",
    "    y = sig_df.index.tolist()\n",
    "    y = [tup1+r'/'+tup2 for tup1, tup2 in y]\n",
    "    plot = [go.Bar(x = sig_df['-log10_BH_pval'].tolist(), marker = dict(color = ['black']*len(sig_df['-log10_BH_pval'].tolist())), name = None, showlegend = False, orientation = 'h', text = y, textposition = 'auto')]\n",
    "    fig = go.Figure(plot)\n",
    "    fig.update_xaxes(title_text = '-log10(BH-corrected P-value)')\n",
    "    fig.update_yaxes(title_text = 'Rank')\n",
    "    fig.write_image('pvalues/Benjamini Hochberg Corrected P-values' + '.png')\n",
    "    fig.write_image('pvalues/Benjamini Hochberg Corrected P-values' + '.svg')\n",
    "    fig.write_image('pvalues/Benjamini Hochberg Corrected P-values' + '.pdf')\n",
    "    iplot(fig)\n",
    "    \n",
    "    display(Markdown(f\"*Figure 4. {top_results} Most Significant Pairwise Intersections (Benjamini-Hochberg Corrected, -log10 transformed)*\"))\n",
    "    display(FileLink('pvalues/log10_BH_Corrected_P-values.csv', result_html_prefix= str(f'Download All {sig_df_size} Significant Corrected P-Values:     ')))\n",
    "    display(FileLink('pvalues/Benjamini Hochberg Corrected P-values.png', result_html_prefix = str(r'Download Figure 3 (PNG):              ')))\n",
    "    display(FileLink('pvalues/Benjamini Hochberg Corrected P-values.svg', result_html_prefix = str(r'Download Figure 3 (SVG):              ')))\n",
    "    display(FileLink('pvalues/Benjamini Hochberg Corrected P-values.pdf', result_html_prefix = str(r'Download Figure 3 (PDF):              ')))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if desc_stat:\n",
    "    plot_BH_sig_pairs(pair_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_occurence(gene_dic):\n",
    "    ##Dictionary where keys are all genes in GMT, value is count of how many sets a gene is in the GMT. \n",
    "    #output: contingency table: first column is # of sets the genes are in, second column is a list of those genes- \n",
    "    count_to_genelist = {}\n",
    "    combine_lsts = []\n",
    "    vals = set(gene_dic.values())\n",
    "    if len(vals) > 10:\n",
    "        combine_lsts = list(vals)[10:]\n",
    "        margin = list(vals)[10]\n",
    "        combined_lst = []\n",
    "    for val in vals:\n",
    "        count_to_genelist[val] = []\n",
    "        for gene in gene_dic:\n",
    "            if gene_dic[gene] == val:\n",
    "                if val in combine_lsts:\n",
    "                     count_to_genelist[margin].append((gene,val))\n",
    "                else:\n",
    "                     count_to_genelist[val].append(gene)\n",
    "                    \n",
    "    \n",
    "    os.makedirs(\"gene_counts\", exist_ok = True)\n",
    "    if len(vals) > 10:\n",
    "        vals = list(vals)[:10]\n",
    "        for val in vals:\n",
    "            size = len(count_to_genelist[val])\n",
    "            lst = count_to_genelist[val]\n",
    "            save_dict = {'Genes': lst}\n",
    "            df = pd.DataFrame(save_dict)\n",
    "            df.to_csv(f\"gene_counts/genes_in_{val}_sets.csv\", index = False)\n",
    "            display(HTML(\"Access  <b> {size} Genes </b> found in exactly <b> {val} sets </b> here:              \".format(size = size, val = val)), FileLink(f'gene_counts/genes_in_{val}_sets.csv'))\n",
    "        \n",
    "        ##save larger sized gene counts into one file\n",
    "        lst = count_to_genelist[margin]\n",
    "        size = len(count_to_genelist[margin])\n",
    "        lst = list(map(list, zip(*lst)))\n",
    "        gene, count = lst\n",
    "        save_dict = {'Genes': gene, 'Count': count}\n",
    "        df = pd.DataFrame(save_dict)\n",
    "        df.to_csv(f\"gene_counts/genes_in_{margin}+_sets.csv\", index = False)\n",
    "        display(HTML(\"Access  <b> {size}  Genes </b> found in <b>  {margin} or more sets  </b> here:              \".format(size = size, margin = margin)), FileLink(f'gene_counts/genes_in_{margin}+_sets.csv'))\n",
    "    else:\n",
    "        \n",
    "        for val in vals:\n",
    "            size = len(count_to_genelist[val])\n",
    "            lst = count_to_genelist[val]\n",
    "            save_dict = {'Genes': lst}\n",
    "            df = pd.DataFrame(save_dict)\n",
    "            df.to_csv(f\"gene_counts/genes_in_{val}_sets.csv\", index = False)\n",
    "            display(HTML(\"Access  <b> {size} Genes </b> found in exactly <b> {val} sets </b> here:              \".format(size = size, val = val)), FileLink(f'gene_counts/genes_in_{val}_sets.csv'))\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desc_stat:\n",
    "    display(Markdown(\"### Gene Occurence\"))\n",
    "    display(Markdown(\"*The following files provide lists of genes that appear in a given number of sets. For instance, the first file provides a list of all genes that appeared in exactly 1 set. For large datasets, genes appearing in many sets are grouped together and downloadable in the last file. This file will provide the both genes and how many sets they appear in.*\"))\n",
    "    display(Markdown(\"**---------------------------------------------------------**\"))\n",
    "    set_occurence(gene_count)\n",
    "    display(Markdown(\"**---------------------------------------------------------**\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_popular_genes(gene_dic, n_popular = 10):\n",
    "    #gene_dic- dictionary where keys represent genes, values are number of sets genes are in\n",
    "    # visualizes the most popular genes\n",
    "    \n",
    "    gene_dic = {'Genes': gene_dic.keys(), 'Counts': gene_dic.values()}\n",
    "    df = pd.DataFrame(gene_dic)\n",
    "    df = df.sort_values(by = 'Counts', ascending = False)[:n_popular]\n",
    "    df = df.sort_values(by = 'Counts', ascending = True)\n",
    "    y = df['Genes']\n",
    "    plot = [go.Bar(x = df['Counts'].tolist(),  name = None, marker = dict(color = ['black']*len(df['Counts'].tolist())), showlegend = False, orientation = 'h', textposition = 'inside', insidetextanchor = 'start', text = y)]\n",
    "    fig = go.Figure(plot)\n",
    "    fig.update_yaxes(title_text = 'Rank')\n",
    "    fig.update_xaxes(title_text = 'Occurence')\n",
    "    iplot(fig)\n",
    "    display(Markdown(f\"*Figure 5. {n_popular} Most Occuring Genes in GMT*\"))\n",
    "    \n",
    "    fig.write_image('gene_stats/Most_popular_genes' + '.png')\n",
    "    fig.write_image('gene_stats/Most_popular_genes' + '.svg')\n",
    "    fig.write_image('gene_stats/Most_popular_genes' + '.pdf')\n",
    "    display(FileLink('gene_stats/Most_popular_genes.png', result_html_prefix = str(r'Download Figure 5 (PNG):              ')))\n",
    "    display(FileLink('gene_stats/Most_popular_genes.svg', result_html_prefix = str(r'Download Figure 5 (SVG):              ')))\n",
    "    display(FileLink('gene_stats/Most_popular_genes.pdf', result_html_prefix = str(r'Download Figure 5 (PDF):              ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if desc_stat:\n",
    "    most_popular_genes(gene_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## 2. Pairwise Intersection Table\n",
    "This section generates an square table, where each row, column is indexed by a gene set term. The numbers in the table correspond to the number of genes found in both gene sets (i.e their intersection). \n",
    "Each non-zero value is a button, which will take you to a csv containing a list of genes in the intersection when clicked. The diagonal of the table is defined as 0, since this is the intersection of a gene set with itself. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"P.I_matrix\", exist_ok = True)\n",
    "if int_tbl:\n",
    "    \n",
    "    html_string = f'''\n",
    "    <html>\n",
    "    <head><title>Intersection Table</title></head>\n",
    "    <body>\n",
    "    {int_df.to_html(render_links = True, escape = False)}\n",
    "    </body>\n",
    "    </html>.\n",
    "    '''\n",
    "    int_df.to_csv('P.I_matrix/intersection_matrix.csv')\n",
    "    display(HTML(html_string))\n",
    "    display(Markdown(\"*Table 2. Pairwise Intersections.*\"))\n",
    "    display(FileLink('P.I_matrix/intersection_matrix.csv', result_html_prefix= str('Download Table 2:   ')))\n",
    "    \n",
    "else:\n",
    "    print('Intersection Table was not requested by user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "\n",
    "## 3.  Network Visualization\n",
    "For GMT files with less than 30 gene sets, a ball and stick network is generated. The nodes of the network represent gene sets, and edges between two nodes represent significant intersections according to the Fisher Exact Test. The thickness of an edge indicates the strength of the test; thicker edges mean a more significant intersection. Hovering over a node will show how many significant intersections a given node has. Clicking on the node will highlight all its edges orange. The nodes may be \"dragged\" around, which may be useful in capturing a good visualization. \n",
    "It should be noted that this visualization is not allowed for files with greater than 30 gene sets, as it becomes uninterpretable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network(df, pair_df):\n",
    "    term_lst = list(df.index)\n",
    "    libraries = list(set(df['Library'].unique()))\n",
    "    num_libs = len(libraries)\n",
    "    \n",
    "    \n",
    "    BH_sig_pairs = list(pair_df.iloc[np.where(pair_df['BH_sig']== True)[0]].index)\n",
    "    BH_sig_vals = list(pair_df.iloc[np.where(pair_df['BH_sig'] == True)[0]]['-log10_BH_pval'])\n",
    "    \n",
    "    \n",
    "    net = Network(notebook= True, cdn_resources = 'remote', font_color = 'black')\n",
    "    net.add_nodes(term_lst)\n",
    "    edge_data = list(zip(BH_sig_pairs, BH_sig_vals))\n",
    "    for pair, pval in edge_data:\n",
    "        src = pair[0]\n",
    "        dst = pair[1]\n",
    "        net.add_edge(src, dst, value = pval)\n",
    "        \n",
    "        \n",
    "    neighbor_map = net.get_adj_list()\n",
    "    lib_color_map = {}\n",
    "    lib_colors = Turbo256[20::256//num_libs-1]\n",
    "    for i, library in enumerate(libraries):\n",
    "        lib_color_map[library] = lib_colors[i]\n",
    "    \n",
    "\n",
    "                  \n",
    "    for i, node in enumerate(net.nodes):\n",
    "        node['title'] = f'Number of Significant Pairwise Intersections: {len(neighbor_map[node[\"id\"]])}'\n",
    "        term = node['id']\n",
    "        term_library = df.loc[term]['Library']\n",
    "        node['color'] = lib_color_map[term_library]\n",
    "\n",
    "    net.set_options(''' var options = {\n",
    "    \"edges\": {\n",
    "    \"color\": {\n",
    "    \"color\": \"lightgrey\",\n",
    "    \"highlight\": \"orange\"\n",
    "    }\n",
    "    },\n",
    "    \"nodes\": {\n",
    "    \"value\": 20\n",
    "    }\n",
    "    }''')\n",
    "    \n",
    "    unique_libs, lib_colors = list(lib_color_map.keys()), list(lib_color_map.values())\n",
    "    \n",
    "    \n",
    "    legend_pos_x = 1000\n",
    "    legend_pos_y = -250\n",
    "    step = 40\n",
    "    legend_nodes = [(str(legend_node),\n",
    "                    {'group': unique_libs[legend_node],\n",
    "                    'label': str(unique_libs[legend_node]), \n",
    "                    'size': 50, \n",
    "                    'fixed': True,\n",
    "                    'physics': True,\n",
    "                    'color': lib_colors[legend_node],\n",
    "                    'x': legend_pos_x, \n",
    "                    'y': f'{legend_pos_y+ legend_node*step}px', \n",
    "                    'shape': 'box'}) for legend_node in range(num_libs)]\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(legend_nodes)\n",
    "    net.from_nx(G)\n",
    "    legend_nodes = net.nodes[-num_libs:]\n",
    "    \n",
    "    new_nodes = []\n",
    "    for i, node in enumerate(legend_nodes):\n",
    "        node['color'] = lib_colors[i]\n",
    "        node['widthConstraint'] = 300\n",
    "        new_nodes.append(node)\n",
    "    net.nodes[-num_libs:] = new_nodes\n",
    "\n",
    "    with open('P.I_matrix/' + 'intersection_network.html', \"w\") as out:\n",
    "        out.write(net.generate_html(notebook=True))\n",
    "\n",
    "    IFrame('P.I_matrix/' + 'intersection_network.html', width = '1000px', height= '600px')\n",
    "\n",
    "\n",
    "    # nx.draw(G, with_labels = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if df.shape[0] < 30:\n",
    "    generate_network(df, pair_df)\n",
    "    display(FileLink('P.I_matrix/' + 'intersection_network.html', result_html_prefix=str('Download Figure 6: ')))\n",
    "else:\n",
    "     print('Unable to Render Network Graph. Please Try again with a smaller dataset')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(Markdown('*Figure 6. Ball and Stick Visualization*'))\n",
    "IFrame('P.I_matrix/' + 'intersection_network.html', width = '1000px', height= '600px')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## 4. Similarity Coefficient Tables\n",
    "This section contains square similarity tables requested by the user. The two tables, jaccard and otsuka- ochiai, contain similarity coefficients. They are downloadable as csv files for further viewing and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jaccard:\n",
    "    display(jac_df)\n",
    "    jac_df.to_csv('P.I_matrix/jaccard_matrix.csv')\n",
    "    display(Markdown(\"*Table 3. Jaccard Coefficient Table.*\"))\n",
    "    display(FileLink('P.I_matrix/jaccard_matrix.csv', result_html_prefix= str('Download Table 3:   ')))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if otoc:\n",
    "    display(otoc_df)\n",
    "    otoc_df.to_csv('P.I_matrix/Otsuka-Ochiai_matrix.csv')\n",
    "    display(Markdown(\"*Table 4. Otsuka-Ochiai Coefficient Table.*\"))\n",
    "    display(FileLink('P.I_matrix/Otsuka-Ochiai_matrix.csv', result_html_prefix= str('Download Table 4:   ')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%appyter markdown\n",
    "## 5. Clustering Visualizations\n",
    "The first visualization is a Uniform Manifold Approximation and Projection (UMAP) Scatter Plot. This visualization groups similar gene sets together into clusters. The color of the points represent the library the gene set is a part of. If the visualization does not appear to have points clustered, but rather scattered randomly across the page, consider changing \"Number of Neighbors\", \"Max df\", or \"Min df\" settings in section 4 of submission page and re-running the notebook. \n",
    "The second visualization is a dendrogram using jaccard distance. The final visualization is a dendrogram using Otsuka-Ochiai distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UMAP_Visualization:\n",
    "\n",
    "    def __init__(self, query_set=[], gene_libraries=[], sig_value=.05, gmt_files=[], gmt_df = []):\n",
    "        self.query_set = [gene.strip() for gene in query_set]\n",
    "        self.gene_libraries = gene_libraries\n",
    "        self.significant_value = sig_value\n",
    "        self.term_library_map = {}\n",
    "        self.dataset = OrderedDict()\n",
    "        self.dataset.update(self.process_gmt_df(gmt_df))\n",
    "        \n",
    "        \n",
    "    def process_gmt_df(self, gmt_df):\n",
    "        if gmt_df == []:\n",
    "            return OrderedDict() ##return the empty Dictionary when no gmt passed in\n",
    "        else:\n",
    "            gmt_df = gmt_df[0]\n",
    "            self.term_library_map.update(pd.Series(gmt_df['Library'].values,index=gmt_df.index.values).to_dict())\n",
    "            return OrderedDict(pd.Series(gmt_df['Genes'].values,index=gmt_df.index.values).to_dict())\n",
    "            \n",
    "   \n",
    "\n",
    "    def process_scatterplot(self, nneighbors=30, mindist=0.1, spread=1.0, maxdf=1.0, mindf=1):\n",
    "        libdict = self.dataset\n",
    "        print(\"\\tTF-IDF vectorizing gene set data...\")\n",
    "        # computes tdfidf score--look this up\n",
    "        vec = TfidfVectorizer(max_df=maxdf, min_df=mindf)\n",
    "        X = vec.fit_transform(libdict.values())\n",
    "        print(X.shape)\n",
    "        adata = anndata.AnnData(X)\n",
    "        adata.obs.index = libdict.keys()\n",
    "\n",
    "        print(\"\\tPerforming Leiden clustering...\")\n",
    "        # the n_neighbors and min_dist parameters can be altered\n",
    "        sc.pp.neighbors(adata, n_neighbors=nneighbors)\n",
    "        sc.tl.leiden(adata, resolution=1.0)\n",
    "        sc.tl.umap(adata, min_dist=mindist, spread=spread, random_state=42)\n",
    "\n",
    "        new_order = adata.obs.sort_values(by='leiden').index.tolist()\n",
    "        adata = adata[new_order, :]\n",
    "        adata.obs['leiden'] = 'Cluster ' + adata.obs['leiden'].astype('object')\n",
    "\n",
    "        df = pd.DataFrame(adata.obsm['X_umap'])\n",
    "        df.columns = ['x', 'y']\n",
    "\n",
    "        df['cluster'] = adata.obs['leiden'].values\n",
    "        df['term'] = adata.obs.index\n",
    "        df['genes'] = [libdict[l] for l in df['term']]\n",
    "        df['library'] = [self.term_library_map[l] for l in df['term']]\n",
    "\n",
    "        return df\n",
    "\n",
    "    def get_scatter_colors(self, df):\n",
    "        clusters = pd.unique(df['library']).tolist()\n",
    "        colors = list(Category20[20])[::2] + list(Category20[20])[1::2]\n",
    "        color_mapper = {clusters[i]: colors[i % 20]\n",
    "                        for i in range(len(clusters))}\n",
    "        return color_mapper\n",
    "\n",
    "    # def get_marker_mapper(self, df):\n",
    "    #     markers = [\"circle\", \"square\", \"triangle\",\n",
    "    #                \"hex\", \"inverted_triangle\", \"diamond\"]\n",
    "    #     libs = pd.unique(df['library']).tolist()\n",
    "    #     marker_mapper = {libs[i]: markers[i] for i in range(len(libs))}\n",
    "    #     return marker_mapper\n",
    "\n",
    "    def get_scatterplot(self, scatterdf):\n",
    "        df = scatterdf.copy()\n",
    "        color_mapper = self.get_scatter_colors(df)\n",
    "        # marker_mapper = self.get_marker_mapper(df)\n",
    "        df['color'] = df['library'].apply(lambda x: color_mapper[x])\n",
    "        # df['marker'] = df['library'].apply(lambda x: marker_mapper[x])\n",
    "\n",
    "        # range_slider = RangeSlider(\"title = Adjust x-axis\",\n",
    "        #                            start=0,\n",
    "        #                            end=10,\n",
    "        #                            step=1)\n",
    "\n",
    "        tooltips = [\n",
    "            (\"Gene Set\", \"@gene_set\"),\n",
    "            (\"Cluster\", \"@cluster\"),\n",
    "            (\"Library\", \"@library\")\n",
    "        ]\n",
    "\n",
    "        hover_emb = HoverTool(tooltips=tooltips)\n",
    "        tools_emb = [hover_emb, 'pan', 'wheel_zoom', 'reset', 'save']\n",
    "\n",
    "        plot_emb = figure(\n",
    "            width=900,\n",
    "            height=700,\n",
    "            tools=tools_emb\n",
    "        )\n",
    "\n",
    "        source = ColumnDataSource(\n",
    "            data=dict(\n",
    "                x=df['x'],\n",
    "                y=df['y'],\n",
    "                gene_set=df['term'],\n",
    "                colors=df['color'],\n",
    "                label=df['library'],\n",
    "                library=df['library'],\n",
    "                cluster = df['cluster']\n",
    "                # markers=df['marker']\n",
    "\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # hide axis labels and grid lines\n",
    "        plot_emb.xaxis.major_tick_line_color = None\n",
    "        plot_emb.xaxis.minor_tick_line_color = None\n",
    "        plot_emb.yaxis.major_tick_line_color = None\n",
    "        plot_emb.yaxis.minor_tick_line_color = None\n",
    "        plot_emb.xaxis.major_label_text_font_size = '0pt'\n",
    "        plot_emb.yaxis.major_label_text_font_size = '0pt'\n",
    "\n",
    "        plot_emb.output_backend = \"svg\"\n",
    "\n",
    "        plot_emb.xaxis.axis_label = \"UMAP_1\"\n",
    "        plot_emb.yaxis.axis_label = \"UMAP_2\"\n",
    "\n",
    "        s = plot_emb.scatter(\n",
    "            'x',\n",
    "            'y',\n",
    "            size=8,\n",
    "            source=source,\n",
    "            legend_group = 'library',\n",
    "            color='colors'\n",
    "            # marker='markers'\n",
    "        )\n",
    "        plot_emb.add_layout(plot_emb.legend[0], 'right')\n",
    "\n",
    "\n",
    "        return plot_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if umap:\n",
    "    umap = UMAP_Visualization(gmt_df = [df])\n",
    "    umap_df = umap.process_scatterplot(maxdf = umap_maxdf, mindf = umap_mindf, nneighbors = umap_num_neighbors)\n",
    "    fig = umap.get_scatterplot(umap_df)\n",
    "    show(fig)\n",
    "    display(Markdown('*Figure 7. Uniform Manifold Approximation Project Scatterplot*'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_library_color_map(df):\n",
    "    colors = list(Category20[20])[::2] + list(Category20[20])[1::2]\n",
    "    libs = pd.unique(df['Library']).tolist()\n",
    "    color_mapper = {libs[i]: colors[i % 20] for i in range(len(libs))} ##library -> color\n",
    "    return color_mapper\n",
    "\n",
    "library_color_map = get_library_color_map(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dendrogram(distance_matrix, df, lnk_method, color_mapper, caption):\n",
    "    assert lnk_method in ['average', 'complete', 'single']\n",
    "    m = distance_matrix.shape[0]\n",
    "    ##inputs: distance matrix (nxn)- in the appyter either otoc_df or jaccard_df will work\n",
    "    ##output: dendrogram which generates new groupings based off of distance matrix data\n",
    "    assert (distance_matrix.shape[0] == distance_matrix.shape[1])\n",
    "    distance_array = distance_matrix.to_numpy()\n",
    "    distance_array = distance_array[np.triu_indices(m, k =1)]## the way linkage takes in a condensed distance matrix\n",
    "    hc_cluster = linkage(distance_array, method = lnk_method)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##color the labels of the dendrogram based off of library association\n",
    "    term_library_map = pd.Series(df['Library'].values,index= df.index.values).to_dict() ##term -> library\n",
    "    libs = pd.unique(df['Library']).tolist()\n",
    "    term_color_map = {t: color_mapper[term_library_map[t]] for t in df.index.values}\n",
    "    fig, ax = plt.subplots()\n",
    "    dendro = dendrogram(hc_cluster, labels = list(df.index.values), color_threshold = 0, above_threshold_color = 'black')\n",
    "    \n",
    "    ##color the labels to corresponding library\n",
    "    dendrogram_labels = ax.xaxis.get_ticklabels() ## get order of Text labels\n",
    "    ordered_labels = [i.get_text() for i in dendrogram_labels] ##get ordered terms\n",
    "    color_list = [term_color_map[i] for i in ordered_labels] ##map color of library to term\n",
    "    [t.set_color(i) for (i,t) in zip(color_list, dendrogram_labels)] ##set color of the ordered terms on plot\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    leg_labs = []\n",
    "    for lib, color in color_mapper.items(): ##create the legend map\n",
    "        patch = mpatches.Patch(color = color, label = lib)\n",
    "        leg_labs.append(patch)\n",
    "    \n",
    "        \n",
    "    \n",
    "    plt.legend(bbox_to_anchor = (-.2, 1), labels = libs, handles = leg_labs, title = \"Libraries Corresponding to Label Color\")\n",
    "    plt.figtext(-.7, -.8, caption, fontdict = {\"style\": \"italic\" })\n",
    "    return dendro\n",
    "\n",
    "    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap(dendro_results, similarity_df, df, color_mapper, caption):\n",
    "    ##\n",
    "    ##inputs: dendro_results: results of running the dendrogram \n",
    "    ## similarity df: similarity dataframe (either otoc or jaccard)\n",
    "    libs = pd.unique(df['Library']).tolist()\n",
    "    fig, ax = plt.subplots(figsize = (12,10))\n",
    "    term_library_map = pd.Series(df['Library'].values,index= df.index.values).to_dict()\n",
    "    term_color_map = {t: color_mapper[term_library_map[t]] for t in df.index.values}\n",
    "    new_order = dendro_results['ivl']\n",
    "    reordered_df = similarity_df.copy()\n",
    "    reordered_df = reordered_df.reindex(new_order)\n",
    "    reordered_df = reordered_df.reindex(new_order, axis= 1)\n",
    "    reordered_df = reordered_df.applymap(lambda x: float(x))\n",
    "    sns.heatmap(reordered_df, xticklabels = 1, ax = ax)\n",
    "    \n",
    "    \n",
    "    term_color_map = {t:  color_mapper[term_library_map[t]] for t in df.index.values}\n",
    "    heatmap_xlabels = ax.xaxis.get_ticklabels()\n",
    "    heatmap_ylabels = ax.yaxis.get_ticklabels()\n",
    "    heatmap_texts = [i.get_text() for i in heatmap_xlabels]\n",
    "    color_list = [term_color_map[i] for i in heatmap_texts] ##map color of library to term\n",
    "    [t.set_color(i) for (i,t) in zip(color_list, heatmap_xlabels)] \n",
    "    [t.set_color(i) for (i,t) in zip(color_list, heatmap_ylabels)]\n",
    "    \n",
    "    leg_labs = []\n",
    "    for lib, color in library_color_map.items():\n",
    "        patch = mpatches.Patch(color = color, label = lib)\n",
    "        leg_labs.append(patch)\n",
    "    \n",
    "    plt.legend(bbox_to_anchor = (-.2, -.1), labels = libs, handles = leg_labs, title = \"Libraries Corresponding to Label Color\")\n",
    "    plt.figtext(-.7, -.4, caption, fontdict = {\"style\": \"italic\", \"fontsize\": \"18\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"dendrograms\", exist_ok = True)\n",
    "if otoc:\n",
    "    distance = lambda x: 1- x.astype(float)\n",
    "    otoc_distance_matrix = otoc_df.apply(distance)\n",
    "    otoc_cluster= generate_dendrogram(otoc_distance_matrix, df, linkage_choice, library_color_map, f\"Figure 8. Hierarchical clustering using {linkage_choice} linkage and otsuka-ochiai Distance\")\n",
    "    plt.savefig('dendrograms/Otsuka_Ochiai_Dendrogram.png', bbox_inches=  'tight')\n",
    "    plt.savefig('dendrograms/Otsuka_Ochiai_Dendrogram.svg', bbox_inches = 'tight')\n",
    "    plt.savefig('dendrograms/Otsuka_Ochiai_Dendrogram.pdf',  bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if otoc:\n",
    "    display(FileLink(f'dendrograms/Otsuka_Ochiai_Dendrogram.png', result_html_prefix = str(f'Download Figure 8. (PNG)           ')))\n",
    "    display(FileLink(f'dendrograms/Otsuka_Ochiai_Dendrogram.svg', result_html_prefix = str(f'Download Figure 8. (SVG)           ')))\n",
    "    display(FileLink(f'dendrograms/Otsuka_Ochiai_Dendrogram.pdf', result_html_prefix = str(f'Download Figure 8. (PDF)           ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jaccard:\n",
    "    jaccard_distance = jac_df.apply(distance)\n",
    "    jac_cluster = generate_dendrogram(jaccard_distance, df, linkage_choice, library_color_map, f\"Figure 9. Hierarchical clustering using {linkage_choice} linkage and jaccard distance\")\n",
    "    plt.savefig('dendrograms/Jaccard_Dendrogram.png', bbox_inches=  'tight')\n",
    "    plt.savefig('dendrograms/Jaccard_Dendrogram.svg', bbox_inches = 'tight')\n",
    "    plt.savefig('dendrograms/Jaccard_Dendrogram.pdf',  bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jaccard:\n",
    "    display(FileLink(f'dendrograms/Jaccard_Dendrogram.png', result_html_prefix = str(f'Download Figure 9. (PNG)           ')))\n",
    "    display(FileLink(f'dendrograms/Jaccard_Dendrogram.svg', result_html_prefix = str(f'Download Figure 9. (SVG)           ')))\n",
    "    display(FileLink(f'dendrograms/Jaccard_Dendrogram.pdf', result_html_prefix = str(f'Download Figure 9. (PDF)           ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"heatmaps\", exist_ok = True)\n",
    "if jaccard:\n",
    "    generate_heatmap(jac_cluster, jac_df, df, library_color_map, \"Figure 10. Jaccard coefficient clustered heatmap\")\n",
    "    plt.savefig('heatmaps/Jaccard_Heatmap.png', bbox_inches=  'tight')\n",
    "    plt.savefig('heatmaps/Jaccard_Heatmap.svg', bbox_inches=  'tight')\n",
    "    plt.savefig('heatmaps/Jaccard_Heatmap.pdf', bbox_inches=  'tight')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if jaccard:\n",
    "    display(FileLink(f'heatmaps/Jaccard_Heatmap.png', result_html_prefix = str(f'Download Figure 10. (PNG)           ')))\n",
    "    display(FileLink(f'heatmaps/Jaccard_Heatmap.svg', result_html_prefix = str(f'Download Figure 10. (SVG)           ')))\n",
    "    display(FileLink(f'heatmaps/Jaccard_Heatmap.pdf', result_html_prefix = str(f'Download Figure 10. (PDF)           ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if otoc:\n",
    "    generate_heatmap(otoc_cluster, otoc_df, df, library_color_map, \"Figure 11. Otsuka-Ochiai coefficient heatmap\")\n",
    "    plt.savefig('heatmaps/Otsuka_Ochiai_Heatmap.png', bbox_inches=  'tight')\n",
    "    plt.savefig('heatmaps/Otsuka_Ochiai_Heatmap.svg', bbox_inches=  'tight')\n",
    "    plt.savefig('heatmaps/Otsuka_Ochiai_Heatmap.pdf', bbox_inches=  'tight')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if otoc:\n",
    "    display(FileLink(f'heatmaps/Otsuka_Ochiai_Heatmap.png', result_html_prefix = str(f'Download Figure 11. (PNG)           ')))\n",
    "    display(FileLink(f'heatmaps/Otsuka_Ochiai_Heatmap.svg', result_html_prefix = str(f'Download Figure 11. (SVG)           ')))\n",
    "    display(FileLink(f'heatmaps/Otsuka_Ochiai_Heatmap.pdf', result_html_prefix = str(f'Download Figure 11. (PDF)           ')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
